{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Citation Scrape\n",
    "This notebook looks at obtaining the citations and their relations from UK Public General Acts (UKPGA).\n",
    "<br><br>\n",
    "This is achieved by loading in a `.csv` file containing all current acts under the category (as of 2022-06-27),\n",
    "then using id of each document to access their official document hosted on [legislation.gov.uk](www.legislation.gov.uk).\n",
    "Each document is stored in an `.xhtml` file format that follows the LegalDocML schema. Using this knowledge, scraping \n",
    "the hosted webpage, searching for `<a></a>` tags that contain `class=\"LegCitation\"` will get every citation found within\n",
    "the document.\n",
    "<br><br>\n",
    "We then look to labelling each citation into their respective relation to the current document. By looking at the\n",
    "parent text surrounding the citation (the text before and after the citation), for the majority of citations, we can\n",
    "identify the relationship. This can be achieved by looking for keywords for the relationship within the text, where a\n",
    "match is found then the citation can be labelled with said relation.\n",
    "<br><br>\n",
    "Finally, all the cited documents and their citation relation graph is then stored in a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 KB 1.7 MB/s eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
      "     -------------------------------------- 139.2/139.2 KB 8.1 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "     -------------------------------------- 160.2/160.2 KB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2022.6.15 charset-normalizer-2.1.0 idna-3.3 requests-2.28.1 urllib3-1.26.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\xukev\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\xukev\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\xukev\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\xukev\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\xukev\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\xukev\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xukev\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\xukev\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Using legacy 'setup.py install' for bs4, since package 'wheel' is not installed.\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "  Running setup.py install for bs4: started\n",
      "  Running setup.py install for bs4: finished with status 'done'\n",
      "Successfully installed beautifulsoup4-4.11.1 bs4-0.0.1 soupsieve-2.3.2.post1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\xukev\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from re import search, IGNORECASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Opening the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### File Paths\n",
    "_\n",
    "_These will need to be updated to match their path on your local system. The relevant files can be found in the 'data' directory._\n",
    "\n",
    "_Default file paths are listed below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LEGISLATION_LIST_FILE_PATH = '../data/legislation.csv' \n",
    "\n",
    "LABEL_FILE_PATH = '../data/labels.txt'\n",
    "\n",
    "CITATION_NETWORK_FILE_PATH = '../data/citation_network.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### List of Legislation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "legislation_df = pd.read_csv(LEGISLATION_LIST_FILE_PATH)\n",
    "legislation_list = zip(legislation_df['type'], legislation_df['year'], legislation_df['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### List of Keywords / Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    with open(LABEL_FILE_PATH, encoding='utf-8') as f:\n",
    "        # Read each line as a new entry into an array\n",
    "        data = f.read().split('\\n')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Opening URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_from_url(doc_id):\n",
    "    # Get the content from the legislation.gov.uk webpage and parse into BeautifulSoup\n",
    "    \n",
    "    url = f'https://www.legislation.gov.uk/{doc_id}/data.xht?view=snippet&wrap=true'\n",
    "    r = requests.get(url)\n",
    "    return BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extraction of Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_citations(doc_soup):\n",
    "    return doc_soup.find_all('a', 'LegCitation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extraction of Parent Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_parent_text(citation_list):\n",
    "    # Get the text surrounding the citation\n",
    "    \n",
    "    citation_passage_list = []\n",
    "    for citation in citation_list:\n",
    "        citation_passage_list.append(citation.parent.parent.text)\n",
    "    return citation_passage_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Labelling of Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Keyword Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def label_citations(citations, parent_text):\n",
    "    # For each citation, look at its parent text and label them according to the keyword found in the text\n",
    "    \n",
    "    labels = get_labels()\n",
    "    citation_passage_label_list = []\n",
    "    for i in range(len(citations)):\n",
    "        passage = parent_text[i]\n",
    "        for label in labels:\n",
    "            if search(label, str(passage), IGNORECASE):\n",
    "                citation_passage_label_list.append([label, citations[i].get('href')])\n",
    "                break\n",
    "    return citation_passage_label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generation of Valid URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_urls(citations):\n",
    "    \"\"\"\n",
    "    The representation of a citation's url can change from document to document. Sometimes it is a full url, sometimes\n",
    "    it is a partial url, other times it can be a url to a webpage other than legislation.gov.uk. This function looks to\n",
    "    standardise the url so the relevant details can be extracted easier.\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    for citation in citations:\n",
    "        valid_citation = True\n",
    "        citation_elements = citation.split('/')\n",
    "\n",
    "        if citation_elements[0] != 'https:' and citation_elements[0] != 'http:':\n",
    "            # Check to see if it is a full url, if not then make it a full url\n",
    "            citation_elements = ('https://www.legislation.gov.uk' + citation).split('/')\n",
    "        else:\n",
    "             if citation_elements[2] == 'www.opsi.gov.uk':\n",
    "                # Check to see if the url points to legislation.gov.uk, if not then make it\n",
    "                citation_elements[2] = 'www.legislation.gov.uk'\n",
    "                citation_elements.pop(3)\n",
    "\n",
    "        if len(citation_elements) < 4:\n",
    "            # If the citation is too short, declare it as an invalid citation\n",
    "            valid_citation = False\n",
    "\n",
    "        elif citation_elements[3] == 'id':\n",
    "            citation_elements.pop(3)\n",
    "\n",
    "        elif citation_elements[3] == 'european':\n",
    "            if citation_elements[4] == 'regulation':\n",
    "                citation_elements[3] = 'eur'\n",
    "            elif citation_elements[4] == 'decision':\n",
    "                citation_elements[3] = 'eudn'\n",
    "            elif citation_elements[4] == 'directive':\n",
    "                citation_elements[3] = 'eudr'\n",
    "            else:\n",
    "                # Raise an error if this type of url has never been seen\n",
    "                raise ValueError(f'Not sure what to do for {\"/\".join(citation_elements)}')\n",
    "            citation_elements.pop(4)\n",
    "\n",
    "        elif citation_elements[3] == 'uksi' or citation_elements[3] == 'ukpga' or citation_elements[3] == 'ukcm' \\\n",
    "                or citation_elements[3] == 'ssi' or citation_elements[3] == 'nisr':\n",
    "            pass\n",
    "\n",
    "        elif citation_elements[3] == 'ukci' and '-' in citation_elements[4]:\n",
    "            valid_citation = False\n",
    "\n",
    "        else:\n",
    "            # Raise an error if this type of url has never been seen\n",
    "            raise ValueError(f'Not sure what to do for {\"/\".join(citation_elements)}')\n",
    "\n",
    "        if valid_citation:\n",
    "            citation_url = '/'.join(citation_elements)\n",
    "            citation_url += '/data.xht?view=snippet&wrap=true'\n",
    "            urls.append(citation_url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Graph Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Creation of CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_graph(header=None):\n",
    "    if not (os.path.exists(CITATION_NETWORK_FILE_PATH)):\n",
    "        # Check to see if graph exists, if not then initialise the file\n",
    "        if header is None:\n",
    "            header = ['source','target','relation']\n",
    "        with open(CITATION_NETWORK_FILE_PATH, 'w') as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerow(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Amending to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_graph(doc_id, citation_urls, labels):\n",
    "    TYPE = 3\n",
    "    YEAR = 4\n",
    "    NUMBER = 5\n",
    "    with open(CITATION_NETWORK_FILE_PATH, 'a') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        doc_id=doc_id.replace(',','')\n",
    "        for i, url in enumerate(citation_urls):\n",
    "            # Add the current document and the target document along with the label of the citation\n",
    "            url = url.replace(',','')\n",
    "            url_list = url.split('/')\n",
    "            target_url = f'{url_list[TYPE]}_{url_list[YEAR]}_{url_list[NUMBER]}'\n",
    "            row = [doc_id, target_url, labels[i]]\n",
    "            csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Main Program\n",
    "\n",
    "_This can take sometime to process as there is a lot of legislation to access and each act can contain **a lot of**\n",
    "citations!_\n",
    "\n",
    "_In total we expect to generate a csv file with around 2million rows_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_graph()\n",
    "\n",
    "for file in legislation_list:\n",
    "    # For each legislation in the list\n",
    "    doc_id = f'{file[0].lower()}/{file[1]}/{file[2]}'\n",
    "    try:\n",
    "        print(f'Opening: {doc_id}')\n",
    "        soup = get_from_url(doc_id) # Get the file\n",
    "        citations = get_citations(soup) # Get the citations in the document\n",
    "        print(f'    Found {len(citations)} citations in document')\n",
    "\n",
    "        if len(citations) != 0:\n",
    "            labelled_citations = label_citations(citations, get_parent_text(citations)) # Label the citations\n",
    "            print(f'    Labelled {len(labelled_citations)} citations in document')\n",
    "\n",
    "            if len(labelled_citations) != len(citations):\n",
    "                print(f'    {len(citations) - len(labelled_citations)} citations not labelled')\n",
    "\n",
    "            if len(labelled_citations) == 0:\n",
    "                print(get_parent_text(citations))\n",
    "            else:\n",
    "                citation_urls = get_data_urls([labelled_citations[i][1] for i, _ in enumerate(labelled_citations)])\n",
    "                labels = [labelled_citations[i][0] for i, _ in enumerate(labelled_citations)]\n",
    "                save_graph(doc_id.replace('/','_'), citation_urls, labels) # Save the citation and the label to the network\n",
    "                print(f'    Successfully saved citations to CSV file')\n",
    "        print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'\\n\"{doc_id}\" failed\\n')\n",
    "        e.with_traceback()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6832110053056925ae86ab0953c551877665044c26fb9a06dd86ef7f3b9b0bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
